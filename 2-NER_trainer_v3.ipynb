{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04706314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=NER_v2\n"
     ]
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,3\" \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "wandb.login()\n",
    "%env WANDB_PROJECT= NER_v2\n",
    "\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995c8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "# https://towardsdatascience.com/fine-tuning-pretrained-nlp-models-with-huggingfaces-trainer-6326a4456e7b\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d834c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "#     _, _, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35abb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 512\n",
    "max_target_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3ab1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/t5-base/resolve/main/spiece.model from cache at /home/HadyElkady/.cache/huggingface/transformers/684a47ca6257e4ca71f0037771464c5b323e945fbc58697d2fad8a7dd1a2f8ba.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-base/resolve/main/tokenizer.json from cache at /home/HadyElkady/.cache/huggingface/transformers/90de37880b5ff5ac7ab70ff0bd369f207e9b74133fa153c163d14c5bb0116207.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "loading file https://huggingface.co/t5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/t5-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/t5-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/HadyElkady/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/HadyElkady/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /home/HadyElkady/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration \n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5d72ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>NE_count</th>\n",
       "      <th>%_NE_in_sentence</th>\n",
       "      <th>input_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He served primarily as a utility infielder dur...</td>\n",
       "      <td>*Major League Baseball*,*St. Louis Cardinals*</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He left alongside top scorer and former captai...</td>\n",
       "      <td>*Fernando Cavenaghi*,*Daniel Passarella*</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In middle age, only if you swim against the cu...</td>\n",
       "      <td>**</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The SecuROM software also caused some virus sc...</td>\n",
       "      <td>*SecuROM*</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From January 2020 , the omnibus moved to ITV3 .</td>\n",
       "      <td>*ITV3*</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157319</th>\n",
       "      <td>The annual Grand National horse race takes pla...</td>\n",
       "      <td>*Grand National*,*Aintree Racecourse*</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157320</th>\n",
       "      <td>Mr. Azoff resigned as head of MCA Records, a u...</td>\n",
       "      <td>*September*,*MCA Records*,*MCA Inc.*,*Warner*,...</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157321</th>\n",
       "      <td>Other disease-causing bacteria in this family ...</td>\n",
       "      <td>*Enterobacter*,*Citrobacter*</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157322</th>\n",
       "      <td>Cercle Brugge 4 0 3 1 4 5 3</td>\n",
       "      <td>*Cercle Brugge*</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157323</th>\n",
       "      <td>`` That obviously means that we wo n't have en...</td>\n",
       "      <td>*Fitzwater*</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157324 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_text  \\\n",
       "0       He served primarily as a utility infielder dur...   \n",
       "1       He left alongside top scorer and former captai...   \n",
       "2       In middle age, only if you swim against the cu...   \n",
       "3       The SecuROM software also caused some virus sc...   \n",
       "4         From January 2020 , the omnibus moved to ITV3 .   \n",
       "...                                                   ...   \n",
       "157319  The annual Grand National horse race takes pla...   \n",
       "157320  Mr. Azoff resigned as head of MCA Records, a u...   \n",
       "157321  Other disease-causing bacteria in this family ...   \n",
       "157322                        Cercle Brugge 4 0 3 1 4 5 3   \n",
       "157323  `` That obviously means that we wo n't have en...   \n",
       "\n",
       "                                              target_text  word_count  \\\n",
       "0           *Major League Baseball*,*St. Louis Cardinals*          25   \n",
       "1                *Fernando Cavenaghi*,*Daniel Passarella*          19   \n",
       "2                                                      **          23   \n",
       "3                                               *SecuROM*          17   \n",
       "4                                                  *ITV3*           8   \n",
       "...                                                   ...         ...   \n",
       "157319              *Grand National*,*Aintree Racecourse*          11   \n",
       "157320  *September*,*MCA Records*,*MCA Inc.*,*Warner*,...          27   \n",
       "157321                       *Enterobacter*,*Citrobacter*          10   \n",
       "157322                                    *Cercle Brugge*           9   \n",
       "157323                                        *Fitzwater*          35   \n",
       "\n",
       "        NE_count  %_NE_in_sentence  input_length  \n",
       "0              6               0.2           155  \n",
       "1              4               0.2           150  \n",
       "2              0               0.0           137  \n",
       "3              1               0.1           113  \n",
       "4              1               0.1            47  \n",
       "...          ...               ...           ...  \n",
       "157319         4               0.4            72  \n",
       "157320         3               0.1           142  \n",
       "157321         2               0.2            92  \n",
       "157322         2               0.2            27  \n",
       "157323         1               0.0           197  \n",
       "\n",
       "[157324 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_sample = training_data.sample(frac=0.4, random_state=1)\n",
    "\n",
    "training_data = pd.read_csv('./1-NER_Data/1-csv_format/train/training_data.csv')\n",
    "# training_data = pd.read_csv('./1-NER_Data/1-csv_format/train/lower_normal_training.csv')\n",
    "\n",
    "training_data = training_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "training_data['input_length'] = training_data['input_text'].apply(lambda x: len(x))\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0cbd42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>NE_count</th>\n",
       "      <th>%_NE_in_sentence</th>\n",
       "      <th>input_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He served primarily as a utility infielder dur...</td>\n",
       "      <td>*Major League Baseball*,*St. Louis Cardinals*</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He left alongside top scorer and former captai...</td>\n",
       "      <td>*Fernando Cavenaghi*,*Daniel Passarella*</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In middle age, only if you swim against the cu...</td>\n",
       "      <td>**</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The SecuROM software also caused some virus sc...</td>\n",
       "      <td>*SecuROM*</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From January 2020 , the omnibus moved to ITV3 .</td>\n",
       "      <td>*ITV3*</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157319</th>\n",
       "      <td>The annual Grand National horse race takes pla...</td>\n",
       "      <td>*Grand National*,*Aintree Racecourse*</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157320</th>\n",
       "      <td>Mr. Azoff resigned as head of MCA Records, a u...</td>\n",
       "      <td>*September*,*MCA Records*,*MCA Inc.*,*Warner*,...</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157321</th>\n",
       "      <td>Other disease-causing bacteria in this family ...</td>\n",
       "      <td>*Enterobacter*,*Citrobacter*</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157322</th>\n",
       "      <td>Cercle Brugge 4 0 3 1 4 5 3</td>\n",
       "      <td>*Cercle Brugge*</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157323</th>\n",
       "      <td>`` That obviously means that we wo n't have en...</td>\n",
       "      <td>*Fitzwater*</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157213 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_text  \\\n",
       "0       He served primarily as a utility infielder dur...   \n",
       "1       He left alongside top scorer and former captai...   \n",
       "2       In middle age, only if you swim against the cu...   \n",
       "3       The SecuROM software also caused some virus sc...   \n",
       "4         From January 2020 , the omnibus moved to ITV3 .   \n",
       "...                                                   ...   \n",
       "157319  The annual Grand National horse race takes pla...   \n",
       "157320  Mr. Azoff resigned as head of MCA Records, a u...   \n",
       "157321  Other disease-causing bacteria in this family ...   \n",
       "157322                        Cercle Brugge 4 0 3 1 4 5 3   \n",
       "157323  `` That obviously means that we wo n't have en...   \n",
       "\n",
       "                                              target_text  word_count  \\\n",
       "0           *Major League Baseball*,*St. Louis Cardinals*          25   \n",
       "1                *Fernando Cavenaghi*,*Daniel Passarella*          19   \n",
       "2                                                      **          23   \n",
       "3                                               *SecuROM*          17   \n",
       "4                                                  *ITV3*           8   \n",
       "...                                                   ...         ...   \n",
       "157319              *Grand National*,*Aintree Racecourse*          11   \n",
       "157320  *September*,*MCA Records*,*MCA Inc.*,*Warner*,...          27   \n",
       "157321                       *Enterobacter*,*Citrobacter*          10   \n",
       "157322                                    *Cercle Brugge*           9   \n",
       "157323                                        *Fitzwater*          35   \n",
       "\n",
       "        NE_count  %_NE_in_sentence  input_length  \n",
       "0              6               0.2           155  \n",
       "1              4               0.2           150  \n",
       "2              0               0.0           137  \n",
       "3              1               0.1           113  \n",
       "4              1               0.1            47  \n",
       "...          ...               ...           ...  \n",
       "157319         4               0.4            72  \n",
       "157320         3               0.1           142  \n",
       "157321         2               0.2            92  \n",
       "157322         2               0.2            27  \n",
       "157323         1               0.0           197  \n",
       "\n",
       "[157213 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = training_data.drop(training_data[training_data['input_length']> 512].index)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2238c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157213\n"
     ]
    }
   ],
   "source": [
    "X_train_tokenized = tokenizer(['ner: ' + sequence for sequence in training_data[\"input_text\"]], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_train_tokenized = tokenizer(list(training_data[\"target_text\"]), \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(training_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b88749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9ecee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>NE_count</th>\n",
       "      <th>%_NE_in_sentence</th>\n",
       "      <th>input_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was always curious what they, the mother and...</td>\n",
       "      <td>**</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In prehistoric times , the region that was to ...</td>\n",
       "      <td>*Assyria*,*Subartu*,*Neanderthal*,*Shanidar Cave*</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But Jesus knew what happened.</td>\n",
       "      <td>**</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He would only appear in four games in two seas...</td>\n",
       "      <td>*AD Ceuta*,*Lorca Deportiva CF*</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cable television is provided by Spectrum .</td>\n",
       "      <td>*Spectrum*</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25917</th>\n",
       "      <td>Previously , WJZ-TV carried the team from thei...</td>\n",
       "      <td>*WJZ-TV*,*Baltimore*</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25918</th>\n",
       "      <td>Israeli defense officials accused Fatah of car...</td>\n",
       "      <td>*Israeli*,*Fatah*</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25919</th>\n",
       "      <td>Hindenburg refused the powers but agreed to th...</td>\n",
       "      <td>*Hindenburg*</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>He finished fourth in the Olympics that year .</td>\n",
       "      <td>*Olympics*</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25921</th>\n",
       "      <td>CHICAGO 65 66 .496 5</td>\n",
       "      <td>*CHICAGO*</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25922 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text  \\\n",
       "0      I was always curious what they, the mother and...   \n",
       "1      In prehistoric times , the region that was to ...   \n",
       "2                          But Jesus knew what happened.   \n",
       "3      He would only appear in four games in two seas...   \n",
       "4             Cable television is provided by Spectrum .   \n",
       "...                                                  ...   \n",
       "25917  Previously , WJZ-TV carried the team from thei...   \n",
       "25918  Israeli defense officials accused Fatah of car...   \n",
       "25919  Hindenburg refused the powers but agreed to th...   \n",
       "25920     He finished fourth in the Olympics that year .   \n",
       "25921                               CHICAGO 65 66 .496 5   \n",
       "\n",
       "                                             target_text  word_count  \\\n",
       "0                                                     **          17   \n",
       "1      *Assyria*,*Subartu*,*Neanderthal*,*Shanidar Cave*          29   \n",
       "2                                                     **           5   \n",
       "3                        *AD Ceuta*,*Lorca Deportiva CF*          25   \n",
       "4                                             *Spectrum*           6   \n",
       "...                                                  ...         ...   \n",
       "25917                               *WJZ-TV*,*Baltimore*          14   \n",
       "25918                                  *Israeli*,*Fatah*          11   \n",
       "25919                                       *Hindenburg*           9   \n",
       "25920                                         *Olympics*           8   \n",
       "25921                                          *CHICAGO*           5   \n",
       "\n",
       "       NE_count  %_NE_in_sentence  input_length  \n",
       "0             0               0.0            90  \n",
       "1             5               0.2           165  \n",
       "2             0               0.0            29  \n",
       "3             5               0.2           150  \n",
       "4             1               0.2            42  \n",
       "...         ...               ...           ...  \n",
       "25917         2               0.1            91  \n",
       "25918         2               0.2            71  \n",
       "25919         1               0.1            58  \n",
       "25920         1               0.1            46  \n",
       "25921         1               0.2            20  \n",
       "\n",
       "[25922 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = pd.read_csv('./1-NER_Data/1-csv_format/val/val_data.csv')\n",
    "validation_data = validation_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "validation_data['input_length'] = validation_data['input_text'].apply(lambda x: len(x))\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd275c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>NE_count</th>\n",
       "      <th>%_NE_in_sentence</th>\n",
       "      <th>input_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was always curious what they, the mother and...</td>\n",
       "      <td>**</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In prehistoric times , the region that was to ...</td>\n",
       "      <td>*Assyria*,*Subartu*,*Neanderthal*,*Shanidar Cave*</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But Jesus knew what happened.</td>\n",
       "      <td>**</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He would only appear in four games in two seas...</td>\n",
       "      <td>*AD Ceuta*,*Lorca Deportiva CF*</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cable television is provided by Spectrum .</td>\n",
       "      <td>*Spectrum*</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25917</th>\n",
       "      <td>Previously , WJZ-TV carried the team from thei...</td>\n",
       "      <td>*WJZ-TV*,*Baltimore*</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25918</th>\n",
       "      <td>Israeli defense officials accused Fatah of car...</td>\n",
       "      <td>*Israeli*,*Fatah*</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25919</th>\n",
       "      <td>Hindenburg refused the powers but agreed to th...</td>\n",
       "      <td>*Hindenburg*</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>He finished fourth in the Olympics that year .</td>\n",
       "      <td>*Olympics*</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25921</th>\n",
       "      <td>CHICAGO 65 66 .496 5</td>\n",
       "      <td>*CHICAGO*</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25913 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text  \\\n",
       "0      I was always curious what they, the mother and...   \n",
       "1      In prehistoric times , the region that was to ...   \n",
       "2                          But Jesus knew what happened.   \n",
       "3      He would only appear in four games in two seas...   \n",
       "4             Cable television is provided by Spectrum .   \n",
       "...                                                  ...   \n",
       "25917  Previously , WJZ-TV carried the team from thei...   \n",
       "25918  Israeli defense officials accused Fatah of car...   \n",
       "25919  Hindenburg refused the powers but agreed to th...   \n",
       "25920     He finished fourth in the Olympics that year .   \n",
       "25921                               CHICAGO 65 66 .496 5   \n",
       "\n",
       "                                             target_text  word_count  \\\n",
       "0                                                     **          17   \n",
       "1      *Assyria*,*Subartu*,*Neanderthal*,*Shanidar Cave*          29   \n",
       "2                                                     **           5   \n",
       "3                        *AD Ceuta*,*Lorca Deportiva CF*          25   \n",
       "4                                             *Spectrum*           6   \n",
       "...                                                  ...         ...   \n",
       "25917                               *WJZ-TV*,*Baltimore*          14   \n",
       "25918                                  *Israeli*,*Fatah*          11   \n",
       "25919                                       *Hindenburg*           9   \n",
       "25920                                         *Olympics*           8   \n",
       "25921                                          *CHICAGO*           5   \n",
       "\n",
       "       NE_count  %_NE_in_sentence  input_length  \n",
       "0             0               0.0            90  \n",
       "1             5               0.2           165  \n",
       "2             0               0.0            29  \n",
       "3             5               0.2           150  \n",
       "4             1               0.2            42  \n",
       "...         ...               ...           ...  \n",
       "25917         2               0.1            91  \n",
       "25918         2               0.2            71  \n",
       "25919         1               0.1            58  \n",
       "25920         1               0.1            46  \n",
       "25921         1               0.2            20  \n",
       "\n",
       "[25913 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = validation_data.drop(validation_data[validation_data['input_length']> 512].index)\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e88974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25913\n"
     ]
    }
   ],
   "source": [
    "X_val_tokenized = tokenizer(['ner: ' + sequence for sequence in validation_data[\"input_text\"]], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_val_tokenized = tokenizer(list(validation_data[\"target_text\"]), \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(validation_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00984097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad38ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(X_val_tokenized, y_val_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef3b6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     \"NER_lower\",\n",
    "#     evaluation_strategy ='steps',\n",
    "#     eval_steps = 500, # Evaluation and Save happens every 500 steps\n",
    "#     save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
    "#     per_device_train_batch_size = 8,\n",
    "#     per_device_eval_batch_size = 8,\n",
    "#     learning_rate = 1e-3,\n",
    "#     adam_epsilon = 1e-8,\n",
    "#     num_train_epochs = 6,\n",
    "#     report_to=\"wandb\",\n",
    "# #     metric_for_best_model = 'f1',\n",
    "#     load_best_model_at_end=True\n",
    "# )\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"NER_normal_diff_eval_steps_patience_5\",\n",
    "#     evaluation_strategy ='epoch',\n",
    "    evaluation_strategy ='steps',\n",
    "    eval_steps = 3743, # Evaluation and Save happens every 3743 steps (steps/(num of epochs*2))\n",
    "#     logging_steps = 500,\n",
    "    save_steps = 3743,\n",
    "    save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
    "    per_device_train_batch_size = 7,\n",
    "    per_device_eval_batch_size = 7,\n",
    "    \n",
    "    \n",
    "    learning_rate = 1e-3,\n",
    "    adam_epsilon = 1e-8,\n",
    "    num_train_epochs = 12,\n",
    "    report_to=\"wandb\",\n",
    "#     metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad5aafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "#     compute_metrics=compute_metrics,\n",
    "    train_dataset= train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 157213\n",
      "  Num Epochs = 12\n",
      "  Instantaneous batch size per device = 7\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 21\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 89844\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/HadyElkady/work/Bachelor_thesis/wandb/run-20220818_220939-1qozxkph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hodz199/NER_v2/runs/1qozxkph\" target=\"_blank\">NER_normal_diff_eval_steps_patience_5</a></strong> to <a href=\"https://wandb.ai/hodz199/NER_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29804' max='89844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29804/89844 7:07:53 < 14:22:02, 1.16 it/s, Epoch 3.98/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3743</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.011776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7486</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.010618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11229</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.009254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14972</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.008492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18715</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22458</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.007756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26201</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.007648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-3743\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-3743/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-3743/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-7486\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-7486/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-7486/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-11229\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-11229/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-11229/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-14972\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-14972/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-14972/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-18715\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-18715/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-18715/pytorch_model.bin\n",
      "Deleting older checkpoint [NER_normal_diff_eval_steps_patience_5/checkpoint-4500] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-22458\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-22458/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-22458/pytorch_model.bin\n",
      "Deleting older checkpoint [NER_normal_diff_eval_steps_patience_5/checkpoint-3743] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25913\n",
      "  Batch size = 21\n",
      "Saving model checkpoint to NER_normal_diff_eval_steps_patience_5/checkpoint-26201\n",
      "Configuration saved in NER_normal_diff_eval_steps_patience_5/checkpoint-26201/config.json\n",
      "Model weights saved in NER_normal_diff_eval_steps_patience_5/checkpoint-26201/pytorch_model.bin\n",
      "Deleting older checkpoint [NER_normal_diff_eval_steps_patience_5/checkpoint-7486] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num examples = 317864\n",
    "# Num Epochs = 3\n",
    "# Instantaneous batch size per device = 8\n",
    "# Total train batch size (w. parallel, distributed & accumulation) = 32\n",
    "# Gradient Accumulation steps = 1\n",
    "# Total optimization steps = 29802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d16b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ner normal ###\n",
    "# number of steps -> 29802\n",
    "# epochs -> 6\n",
    "# patience -> 5\n",
    "# eval_steps = 1000\n",
    "# save_steps = 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
