{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d155684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\" \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import requests\n",
    "import time\n",
    "\n",
    "wandb.login()\n",
    "%env WANDB_PROJECT= Relation_Lining\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_label(rel_id):\n",
    "    label = ''\n",
    "    API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        'action': 'wbgetentities',\n",
    "        'format': 'json',\n",
    "        'languages': 'en',\n",
    "        'props': 'labels',\n",
    "        'ids': ''\n",
    "    }\n",
    "      \n",
    "    params['ids'] = str(rel_id)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(API_ENDPOINT, params = params).json()['entities']\n",
    "        label = response[str(rel_id)]['labels']['en']['value']\n",
    "    except:\n",
    "        return label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import inspect\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def parallal_task(func, iterable, *params): \n",
    "    with open(f'./tmp_func.py', 'w') as file:\n",
    "        file.write(\"import requests \\n\")\n",
    "        file.write(inspect.getsource(func).replace(func.__name__, 'task'))\n",
    "\n",
    "    from tmp_func import task\n",
    "    pool = Pool(processes=15)\n",
    "    res = pool.map(task, iterable)\n",
    "    pool.close()\n",
    "    \n",
    "    os.remove('./tmp_func.py')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "# https://towardsdatascience.com/fine-tuning-pretrained-nlp-models-with-huggingfaces-trainer-6326a4456e7b\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e827f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 4048\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration \n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf5b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac110a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./3-Relation_Linking_Data/1-csv_format/training_data.csv')\n",
    "training_data = training_data.dropna()\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# training_data['target relation label'] = parallal_task(get_relation_label, list(training_data['target relation id']))\n",
    "# print(time.time() - start)\n",
    "# training_data.to_csv('./3-Relation_Linking_Data/1-csv_format/training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['input_text'] = '**' + training_data['question'] + '**,**' + training_data['relation labels'] + '**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a537834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(training_data['input_text'].str.len(), bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data['input_text'][training_data['input_text'].str.len() > 1800])*100/len(training_data['input_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20170844",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data[training_data['input_text'].str.len() <= 4048])/len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data['input_text'].str.len() <= 2024]\n",
    "training_data = training_data.sample(frac=1, random_state=1)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31147a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = list(training_data['input_text'])\n",
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56664661",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = list(training_data['target relation label'].astype(str))\n",
    "target_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(['relation_linking: ' + sequence for sequence in input_text], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_train_tokenized = tokenizer(target_text, \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(training_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176933df",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv('./3-Relation_Linking_Data/1-csv_format/validation_data.csv')\n",
    "validation_data\n",
    "print(len(validation_data))\n",
    "validation_data = validation_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# validation_data['target relation label'] = parallal_task(get_relation_label, list(validation_data['target relation id']))\n",
    "# print(time.time() - start)\n",
    "# validation_data.to_csv('./3-Relation_Linking_Data/1-csv_format/validation_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c589d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['input_text'] = '**' + validation_data['question'] + '**,**' + validation_data['relation labels'] + '**'\n",
    "validation_data = validation_data[validation_data['input_text'].str.len() <= 1700]\n",
    "validation_data = validation_data.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d172a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_val = validation_data['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text_val = list(validation_data['target relation label'].astype(str))\n",
    "target_text_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tokenized = tokenizer(['relation_linking: ' + sequence for sequence in input_text_val], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_val_tokenized = tokenizer(target_text_val, \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(validation_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(X_val_tokenized, y_val_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91720d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"Relation_linking_without_entity_higher_patience\",\n",
    "    evaluation_strategy ='steps',\n",
    "    eval_steps = 100, # Evaluation and Save happens every 50 steps\n",
    "    logging_steps = 100,\n",
    "    save_steps = 100,\n",
    "    save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    learning_rate = 1e-3,\n",
    "    adam_epsilon = 1e-8,\n",
    "    num_train_epochs = 5,\n",
    "    report_to=\"wandb\",\n",
    "#     metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset= train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "#     callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=6)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
