{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aed85b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhodz199\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=NEL\n"
     ]
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,3\" \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.login()\n",
    "%env WANDB_PROJECT=NEL\n",
    "# wandb.init(project=\"NEL\")\n",
    "\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbbafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "# https://towardsdatascience.com/fine-tuning-pretrained-nlp-models-with-huggingfaces-trainer-6326a4456e7b\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58dfe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 1024\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e889df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration \n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecf43f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>entity</th>\n",
       "      <th>wikidata_reply</th>\n",
       "      <th>qid_in_reply</th>\n",
       "      <th>input_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>Q7492362</td>\n",
       "      <td>**Who was involved in the sheemore ambush?**</td>\n",
       "      <td>**sheemore ambush**</td>\n",
       "      <td>**[[Q7492362, Sheemore ambush, ambush during t...</td>\n",
       "      <td>True</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>Q82955</td>\n",
       "      <td>**name a professional politician.**</td>\n",
       "      <td>**politician**</td>\n",
       "      <td>**[[Q51556674, Politician, song by Cream], [Q1...</td>\n",
       "      <td>True</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92904</th>\n",
       "      <td>Q738653</td>\n",
       "      <td>** white can play either a3 or a4 (see algebra...</td>\n",
       "      <td>**algebraic notation**</td>\n",
       "      <td>**[[Q60418499, Algebraic Notation of Kinship, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20220</th>\n",
       "      <td>Q4776569</td>\n",
       "      <td>**Where in europe was antonio demo born**</td>\n",
       "      <td>**antonio demo**</td>\n",
       "      <td>**[[Q4776569, Antonio Demo, Italian-American p...</td>\n",
       "      <td>True</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105441</th>\n",
       "      <td>Q1297</td>\n",
       "      <td>** Filming. Prior to filming, Mendes sought to...</td>\n",
       "      <td>**Chicago**</td>\n",
       "      <td>**[[Q2233885, Willard, city in Huron County, O...</td>\n",
       "      <td>True</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98047</th>\n",
       "      <td>Q816704</td>\n",
       "      <td>** the Daily Mirror's new magazine. Their Depu...</td>\n",
       "      <td>**pâté**</td>\n",
       "      <td>**[[Q1044124, paten, small plate used to hold ...</td>\n",
       "      <td>True</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Q2247706</td>\n",
       "      <td>**who directed the crowd roars**</td>\n",
       "      <td>**the crowd roars**</td>\n",
       "      <td>**[[Q2247706, The Crowd Roars, 1938 film by Ri...</td>\n",
       "      <td>True</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77708</th>\n",
       "      <td>Q100047</td>\n",
       "      <td>**AmIRC is an MUI-based IRC client for the Ami...</td>\n",
       "      <td>**Amiga**</td>\n",
       "      <td>**[[Q20049564, Amiga, song by Eliana], [Q32389...</td>\n",
       "      <td>True</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98539</th>\n",
       "      <td>Q2717</td>\n",
       "      <td>** place). Births. March 25 - Matthew Barney, ...</td>\n",
       "      <td>**July 29**</td>\n",
       "      <td>**[[Q17982661, 29 July 2013, date], [Q17982659...</td>\n",
       "      <td>True</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>Q180089</td>\n",
       "      <td>** any Ann Coulter book. It isn't what the Ama...</td>\n",
       "      <td>**the Economist**</td>\n",
       "      <td>**[[Q100293480, The Economist, newspaper publi...</td>\n",
       "      <td>True</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130395 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid                                           question  \\\n",
       "4312    Q7492362       **Who was involved in the sheemore ambush?**   \n",
       "12486     Q82955                **name a professional politician.**   \n",
       "92904    Q738653  ** white can play either a3 or a4 (see algebra...   \n",
       "20220   Q4776569          **Where in europe was antonio demo born**   \n",
       "105441     Q1297  ** Filming. Prior to filming, Mendes sought to...   \n",
       "...          ...                                                ...   \n",
       "98047    Q816704  ** the Daily Mirror's new magazine. Their Depu...   \n",
       "5192    Q2247706                   **who directed the crowd roars**   \n",
       "77708    Q100047  **AmIRC is an MUI-based IRC client for the Ami...   \n",
       "98539      Q2717  ** place). Births. March 25 - Matthew Barney, ...   \n",
       "128037   Q180089  ** any Ann Coulter book. It isn't what the Ama...   \n",
       "\n",
       "                        entity  \\\n",
       "4312       **sheemore ambush**   \n",
       "12486           **politician**   \n",
       "92904   **algebraic notation**   \n",
       "20220         **antonio demo**   \n",
       "105441             **Chicago**   \n",
       "...                        ...   \n",
       "98047                 **pâté**   \n",
       "5192       **the crowd roars**   \n",
       "77708                **Amiga**   \n",
       "98539              **July 29**   \n",
       "128037       **the Economist**   \n",
       "\n",
       "                                           wikidata_reply  qid_in_reply  \\\n",
       "4312    **[[Q7492362, Sheemore ambush, ambush during t...          True   \n",
       "12486   **[[Q51556674, Politician, song by Cream], [Q1...          True   \n",
       "92904   **[[Q60418499, Algebraic Notation of Kinship, ...          True   \n",
       "20220   **[[Q4776569, Antonio Demo, Italian-American p...          True   \n",
       "105441  **[[Q2233885, Willard, city in Huron County, O...          True   \n",
       "...                                                   ...           ...   \n",
       "98047   **[[Q1044124, paten, small plate used to hold ...          True   \n",
       "5192    **[[Q2247706, The Crowd Roars, 1938 film by Ri...          True   \n",
       "77708   **[[Q20049564, Amiga, song by Eliana], [Q32389...          True   \n",
       "98539   **[[Q17982661, 29 July 2013, date], [Q17982659...          True   \n",
       "128037  **[[Q100293480, The Economist, newspaper publi...          True   \n",
       "\n",
       "        input_len  \n",
       "4312          143  \n",
       "12486         531  \n",
       "92904         622  \n",
       "20220         114  \n",
       "105441        629  \n",
       "...           ...  \n",
       "98047         790  \n",
       "5192          224  \n",
       "77708         470  \n",
       "98539         515  \n",
       "128037        586  \n",
       "\n",
       "[130395 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('./2-NEL_Data/2-csv_format_2/training_data_shuffled.csv')\n",
    "training_data = training_data.sample(frac=1, random_state=1)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36e60eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Who was involved in the sheemore ambush?**,**sheemore ambush**,**[[Q7492362, Sheemore ambush, ambush during the Irish War of Independence]]**'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = list(training_data['question'] + ',' + training_data['entity'] + ',' + training_data['wikidata_reply'])\n",
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d81b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q7492362'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text = list(training_data['qid'])\n",
    "target_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4041a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130395\n"
     ]
    }
   ],
   "source": [
    "X_train_tokenized = tokenizer(['nel: ' + sequence for sequence in input_text], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_train_tokenized = tokenizer(target_text, \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(training_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fba15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84e0e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>entity</th>\n",
       "      <th>wikidata_reply</th>\n",
       "      <th>qid_in_reply</th>\n",
       "      <th>input_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13761</th>\n",
       "      <td>Q497</td>\n",
       "      <td>** arises from the anus, the distal orifice of...</td>\n",
       "      <td>**anus**</td>\n",
       "      <td>**[[Q31785909, Anus, mountain in Namibia], [Q4...</td>\n",
       "      <td>True</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>Q188</td>\n",
       "      <td>**Hiwi is a German abbreviation. It has two me...</td>\n",
       "      <td>**German**</td>\n",
       "      <td>**[[Q188, German, West Germanic language spoke...</td>\n",
       "      <td>True</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Q11865151</td>\n",
       "      <td>**what country is ismo kallio from**</td>\n",
       "      <td>**ismo kallio**</td>\n",
       "      <td>**[[Q11865151, Ismo Kallio, Finnish actor (193...</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>Q165654</td>\n",
       "      <td>** The fire was first spotted at 8:04 p.m. by ...</td>\n",
       "      <td>**constable**</td>\n",
       "      <td>**[[Q159297, John Constable, English painter (...</td>\n",
       "      <td>True</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510</th>\n",
       "      <td>Q81136</td>\n",
       "      <td>** the British Admiralty lost interest in the ...</td>\n",
       "      <td>**Northwest Passage**</td>\n",
       "      <td>**[[Q17114554, Northwest Passage, former bi-we...</td>\n",
       "      <td>True</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Q7697846</td>\n",
       "      <td>**what type of film is telstar: the joe meek s...</td>\n",
       "      <td>**telstar: the joe meek story**</td>\n",
       "      <td>**[[Q7697846, Telstar: The Joe Meek Story, 200...</td>\n",
       "      <td>True</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Q252</td>\n",
       "      <td>**Bunguran is a small archipelago of Indonesia...</td>\n",
       "      <td>**Indonesia**</td>\n",
       "      <td>**[[Q96708780, Indonesia, scientific journal],...</td>\n",
       "      <td>True</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>Q5758978</td>\n",
       "      <td>**American High is a documentary television sh...</td>\n",
       "      <td>**Highland Park High School**</td>\n",
       "      <td>**[[Q5758983, Highland Park High School, publi...</td>\n",
       "      <td>True</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Q2605094</td>\n",
       "      <td>**What type of music is the album hours?**</td>\n",
       "      <td>**hours**</td>\n",
       "      <td>**[[Q25235, hour, unit of time], [Q157044, The...</td>\n",
       "      <td>True</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>Q40861</td>\n",
       "      <td>**marble and other kinds of stone are usually ...</td>\n",
       "      <td>**marble**</td>\n",
       "      <td>**[[Q662804, Marble, town in Gunnison County, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14406 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid                                           question  \\\n",
       "13761       Q497  ** arises from the anus, the distal orifice of...   \n",
       "12966       Q188  **Hiwi is a German abbreviation. It has two me...   \n",
       "135    Q11865151               **what country is ismo kallio from**   \n",
       "13518    Q165654  ** The fire was first spotted at 8:04 p.m. by ...   \n",
       "10510     Q81136  ** the British Admiralty lost interest in the ...   \n",
       "...          ...                                                ...   \n",
       "905     Q7697846  **what type of film is telstar: the joe meek s...   \n",
       "5192        Q252  **Bunguran is a small archipelago of Indonesia...   \n",
       "12172   Q5758978  **American High is a documentary television sh...   \n",
       "235     Q2605094         **What type of music is the album hours?**   \n",
       "13349     Q40861  **marble and other kinds of stone are usually ...   \n",
       "\n",
       "                                entity  \\\n",
       "13761                         **anus**   \n",
       "12966                       **German**   \n",
       "135                    **ismo kallio**   \n",
       "13518                    **constable**   \n",
       "10510            **Northwest Passage**   \n",
       "...                                ...   \n",
       "905    **telstar: the joe meek story**   \n",
       "5192                     **Indonesia**   \n",
       "12172    **Highland Park High School**   \n",
       "235                          **hours**   \n",
       "13349                       **marble**   \n",
       "\n",
       "                                          wikidata_reply  qid_in_reply  \\\n",
       "13761  **[[Q31785909, Anus, mountain in Namibia], [Q4...          True   \n",
       "12966  **[[Q188, German, West Germanic language spoke...          True   \n",
       "135    **[[Q11865151, Ismo Kallio, Finnish actor (193...          True   \n",
       "13518  **[[Q159297, John Constable, English painter (...          True   \n",
       "10510  **[[Q17114554, Northwest Passage, former bi-we...          True   \n",
       "...                                                  ...           ...   \n",
       "905    **[[Q7697846, Telstar: The Joe Meek Story, 200...          True   \n",
       "5192   **[[Q96708780, Indonesia, scientific journal],...          True   \n",
       "12172  **[[Q5758983, Highland Park High School, publi...          True   \n",
       "235    **[[Q25235, hour, unit of time], [Q157044, The...          True   \n",
       "13349  **[[Q662804, Marble, town in Gunnison County, ...          True   \n",
       "\n",
       "       input_len  \n",
       "13761        532  \n",
       "12966        459  \n",
       "135          110  \n",
       "13518        592  \n",
       "10510        659  \n",
       "...          ...  \n",
       "905          156  \n",
       "5192         507  \n",
       "12172        661  \n",
       "235          466  \n",
       "13349        646  \n",
       "\n",
       "[14406 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv('./2-NEL_Data/2-csv_format_2/val_data_shuffled.csv')\n",
    "val_data = val_data.sample(frac=1, random_state=1)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce817b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** arises from the anus, the distal orifice of the gastrointestinal tract. It is a distinct entity from the more common colorectal cancer. The etiology, risk factors, clinical progression, staging, **,**anus**,**[[Q31785909, Anus, mountain in Namibia], [Q497, anus, digestive track waste expulsion opening], [Q23855, Anus, Oceanic language spoken in Indonesia], [Q20685927, Anus, album by Alaska Thunderfuck 5000], [Q25016777, Pulau Anus, island in Papua, Indonesia], [Q26235245, Anus, village in Sarmi Regency, Papua, Indonesia]]**'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_val = list(val_data['question'] + ',' + val_data['entity'] + ',' + val_data['wikidata_reply'])\n",
    "input_text_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5529021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q497'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_val = list(val_data['qid'])\n",
    "target_text_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb81f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14406\n"
     ]
    }
   ],
   "source": [
    "X_val_tokenized = tokenizer(['nel: ' + sequence for sequence in input_text_val], \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_source_length)\n",
    "\n",
    "y_val_tokenized = tokenizer(target_text_val, \n",
    "                              padding=True, \n",
    "                              truncation=True, \n",
    "                              max_length=max_target_length)\n",
    "\n",
    "print(len(val_data))\n",
    "# print(len(training_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347eb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26b6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27199565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31988db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(X_val_tokenized, y_val_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2c3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"NEL_model_shuffled_add_spaces_in_input\",\n",
    "    evaluation_strategy ='steps',\n",
    "    eval_steps = 1000, # Evaluation and Save happens every 50 steps\n",
    "    logging_steps = 1000,\n",
    "    save_steps = 1000,\n",
    "    save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
    "    per_device_train_batch_size = 4,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    learning_rate = 1e-3,\n",
    "    adam_epsilon = 1e-8,\n",
    "    num_train_epochs = 5,\n",
    "    report_to=\"wandb\",\n",
    "#     metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff7fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset= train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac4c631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 130395\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54335\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/HadyElkady/work/Bachelor_thesis/wandb/run-20220813_045736-dflz8g32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hodz199/NEL/runs/dflz8g32\" target=\"_blank\">NEL_model_shuffled</a></strong> to <a href=\"https://wandb.ai/hodz199/NEL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37000' max='54335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37000/54335 11:27:34 < 5:22:09, 0.90 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.251185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.166507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.132703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.121042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.131296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.118089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.107417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.103013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.100113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.092724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.089665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.096058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.083039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.096592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.083259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.076988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.085343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.074242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.077863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.082429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.080328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.077579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.072688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.076495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.077649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.072871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.066658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.065201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.064803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.063752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.070482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.067264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.064207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.069986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.066747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-1000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-1000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-1000/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-2000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-2000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-2000/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-3000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-3000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-3000/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-4000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-4000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-4000/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-5000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-5000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-5000/pytorch_model.bin\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-6000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-6000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-1000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-7000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-7000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-2000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-8000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-8000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-3000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-9000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-9000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-4000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-10000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-10000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-5000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-11000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-11000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-6000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-12000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-12000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-7000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-13000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-13000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-8000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-14000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-14000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-9000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-15000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-15000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-10000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-16000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-16000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-11000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-17000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-17000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-12000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-18000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-18000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-13000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-19000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-19000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-14000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-20000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-20000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-15000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-21000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-21000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-16000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-22000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-22000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-17000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-23000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-23000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-18000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-24000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-24000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-19000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-25000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-25000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-20000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-26000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-26000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-26000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-21000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-27000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-27000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-22000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-28000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-28000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-23000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-29000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-29000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-24000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-30000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-30000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-25000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-31000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-31000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-26000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-32000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-32000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-27000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-33000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-33000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-33000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-28000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-34000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-34000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-34000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-29000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-35000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-35000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-35000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-30000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-36000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-36000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-36000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-31000] due to args.save_total_limit\n",
      "/home/HadyElkady/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14406\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to NEL_model_shuffled/checkpoint-37000\n",
      "Configuration saved in NEL_model_shuffled/checkpoint-37000/config.json\n",
      "Model weights saved in NEL_model_shuffled/checkpoint-37000/pytorch_model.bin\n",
      "Deleting older checkpoint [NEL_model_shuffled/checkpoint-33000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from NEL_model_shuffled/checkpoint-32000 (score: 0.06375224143266678).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37000, training_loss=0.09810885846937024, metrics={'train_runtime': 41263.5624, 'train_samples_per_second': 15.8, 'train_steps_per_second': 1.317, 'total_flos': 2.6085598750688256e+17, 'train_loss': 0.09810885846937024, 'epoch': 3.4})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a4dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef8c4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num examples = 130395\n",
    "# Num Epochs = 5\n",
    "# Instantaneous batch size per device = 4\n",
    "# Total train batch size (w. parallel, distributed & accumulation) = 12\n",
    "# Gradient Accumulation steps = 1\n",
    "# Total optimization steps = 54335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4564a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
